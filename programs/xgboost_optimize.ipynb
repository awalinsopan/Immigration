{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from astropy.time import Time\n",
    "from scipy import interpolate\n",
    "from scipy.stats import spearmanr\n",
    "import matplotlib.pyplot as plot\n",
    "from geopy.distance import distance as gdistance\n",
    "from sklearn.preprocessing import StandardScaler as SCALER\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import immigration_data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate,GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, roc_auc_score\n",
    "import xgboost as xgb\n",
    "import get_best_xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import immigration_data\n",
    "import importlib\n",
    "importlib.reload(immigration_data)\n",
    "imm = immigration_data.immigration_data(nyears_lookback = 1)\n",
    "X,y,d = imm.get_training_data()\n",
    "year_pred = imm.year_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can not use standard cross validation as this is temporally ordered data. Below is a walk-forward cross validation scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_immigration_data(clf, X, y, year_pred):\n",
    "\n",
    "    score = []\n",
    "    year = 2004 + np.arange(14)\n",
    "    for ye in year:\n",
    "        ind_test = year_pred == ye\n",
    "        ind_train = (year_pred < ye) \n",
    "        Xtrain = X[ind_train, :]\n",
    "        ytrain = y[ind_train]\n",
    "        Xtest = X[ind_test, :]\n",
    "        ytest = y[ind_test]\n",
    "        clf.fit(Xtrain, ytrain)\n",
    "        ypred = clf.predict(Xtest)\n",
    "        rr = roc_auc_score(ytest, ypred)\n",
    "        score.append(rr)\n",
    "    \n",
    "\n",
    "    score_out = np.mean(score)\n",
    "    \n",
    "    return score_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the hyper parameter optimization code. Additional hyper parameters may be added to the space if desired. The results of this run are hard-coded into get_best_xgb_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [8:53:54<00:00, 76.81s/it, best loss: -0.6268685984779628]    \n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK, space_eval\n",
    "\n",
    "def objective(para):\n",
    "    # print(para['max_depth'],para['learning_rate'])\n",
    "    clf = xgb.XGBClassifier(**para, objective='binary:logistic')\n",
    "\n",
    "    testScore = CV_immigration_data(clf, X, y, year_pred)\n",
    "    #print(testScore)\n",
    "    return {'loss': -1 * testScore, 'status': STATUS_OK}\n",
    "                                \n",
    "\n",
    "trials = Trials()\n",
    "space = {\n",
    "            'learning_rate':    hp.choice('learning_rate',    np.arange(0.01, 0.21, 0.02)),\n",
    "            'max_depth':        hp.choice('max_depth',        np.arange(3, 16, 1, dtype=int)),\n",
    "            'min_child_weight': hp.choice('min_child_weight', np.arange(1, 8, 1, dtype=int)),\n",
    "            'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.3, 0.8, 0.1)),\n",
    "            'subsample':        hp.uniform('subsample', 0.8, 1),\n",
    "            'n_estimators':     hp.choice('n_estimators', np.arange(1,100,1)),\n",
    "            'gamma' :           hp.choice('gamma', [0,0.5, 1,2.5, 5, 10]), \n",
    "            'alpha' :           hp.choice('alpha', [0, 1e-5, 1e-3, 1e-1, 1, 5, 10])}\n",
    "result = fmin(fn = objective, space = space, algo = tpe.suggest,\n",
    "                      trials=trials, max_evals=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the best parameters which are hard-coded into get_best_xgb_model.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "        para = {'alpha': 5, \n",
    "                'colsample_bytree': 0.4, \n",
    "                'gamma': 10, \n",
    "                'learning_rate': 0.12999999999999998, \n",
    "                'max_depth': 7, \n",
    "                'min_child_weight': 5, \n",
    "                'n_estimators': 46, \n",
    "                'subsample': 0.8779937359366555}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
